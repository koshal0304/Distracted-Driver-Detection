{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5e352f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import secrets\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e0fd548",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\kabeer\\\\Desktop\\\\ddd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b25cf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DIR = os.path.join(os.getcwd(),\"test\")\n",
    "TRAIN_DIR = os.path.join(os.getcwd(),\"train\")\n",
    "MODEL_PATH = os.path.join(os.getcwd(),\"model\",\"self_trained\")\n",
    "PICKLE_DIR = os.path.join(os.getcwd(),\"pickle_files\")\n",
    "CSV_DIR = os.path.join(os.getcwd(),\"csv_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e04d0eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(TEST_DIR):\n",
    "    print(\"Testing data does not exists\")\n",
    "if not os.path.exists(TRAIN_DIR):\n",
    "    print(\"Training data does not exists\")\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    print(\"Model path does not exists\")\n",
    "    os.makedirs(MODEL_PATH)\n",
    "    print(\"Model path created\")\n",
    "if not os.path.exists(PICKLE_DIR):\n",
    "    os.makedirs(PICKLE_DIR)\n",
    "if not os.path.exists(CSV_DIR):\n",
    "    os.makedirs(CSV_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55fe03f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the data augmentation definition\n",
    "\n",
    "gen_per_image = 1\n",
    "gen_per_class = 200\n",
    "rotation_range = 5\n",
    "width_shift_range = 0.02\n",
    "height_shift_range = 0.02\n",
    "shear_range = 0.01\n",
    "zoom_range = 0.05\n",
    "horizontal_flip = False\n",
    "fill_mode = \"nearest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e82974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "height_shift_range = 0.02\n",
    "shear_range = 0.01\n",
    "zoom_range = 0.05\n",
    "horizontal_flip = False\n",
    "fill_mode = \"nearest\"\n",
    "\n",
    "def increase_brightness(img, value):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "\n",
    "    lim = 255 - value\n",
    "    v[v > lim] = 255\n",
    "    v[v <= lim] += value\n",
    "\n",
    "    final_hsv = cv2.merge((h, s, v))\n",
    "    img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
    "    return img\n",
    "\n",
    "def change_contrast(img, level):\n",
    "    img = Image.fromarray(img.astype('uint8'))\n",
    "    factor = (259 * (level + 255)) / (255 * (259 - level))\n",
    "    def contrast(c):\n",
    "        return 128 + factor * (c - 128)\n",
    "    return np.array(img.point(contrast))\n",
    "\n",
    "def pad_img(img):\n",
    "    h, w = img.shape[:2]\n",
    "    new_h = int((5 + secrets.randbelow(16)) * h / 100) + h\n",
    "    new_w = int((5 + secrets.randbelow(16)) * w / 100) + w\n",
    "\n",
    "    full_sheet = np.ones((new_h, new_w, 3)) * 255\n",
    "\n",
    "    p_X = secrets.randbelow(new_h - img.shape[0])\n",
    "    p_Y = secrets.randbelow(new_w - img.shape[1])\n",
    "\n",
    "    full_sheet[p_X : p_X + img.shape[0], p_Y : p_Y + img.shape[1]] = img\n",
    "\n",
    "    full_sheet = cv2.resize(full_sheet, (w, h), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    return full_sheet.astype(np.uint8)\n",
    "\n",
    "def preprocess_img(img):\n",
    "    img = np.array(img)\n",
    "\n",
    "    x = secrets.randbelow(2)\n",
    "\n",
    "    if x == 0:\n",
    "        # img = pad_img(img)\n",
    "        img = increase_brightness(img, secrets.randbelow(26))\n",
    "        img = change_contrast(img, secrets.randbelow(51))\n",
    "    else:\n",
    "        # img = pad_img(img)\n",
    "        img = change_contrast(img, secrets.randbelow(51))\n",
    "        img = increase_brightness(img, secrets.randbelow(26))\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0817c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "IMAGE_SIZE = 224\n",
    "NUM_EPOCH = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c5b843b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17943 images belonging to 10 classes.\n",
      "Found 4481 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "#Initialise the parameters for Augmentation.\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range = rotation_range,\n",
    "        width_shift_range = width_shift_range,\n",
    "        height_shift_range = height_shift_range,\n",
    "        shear_range = shear_range,\n",
    "        zoom_range = zoom_range,\n",
    "        horizontal_flip = horizontal_flip,\n",
    "        fill_mode = fill_mode,\n",
    "        validation_split = 0.2,\n",
    "        preprocessing_function = preprocess_img)\n",
    "\n",
    "\n",
    "train_data = datagen.flow_from_directory(TRAIN_DIR,\n",
    "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                        batch_size=BATCH_SIZE,\n",
    "                                        subset='training',shuffle=False)\n",
    "\n",
    "valid_data = datagen.flow_from_directory(TRAIN_DIR,\n",
    "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                        batch_size=BATCH_SIZE,\n",
    "                                        subset='validation',shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f22f6dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 224, 224, 64)      832       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 112, 112, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 112, 112, 128)     32896     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 56, 56, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 56, 56, 256)       131328    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 28, 28, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 512)       524800    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 14, 14, 512)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 100352)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 500)               50176500  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,871,366\n",
      "Trainable params: 50,871,366\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(IMAGE_SIZE,IMAGE_SIZE,3), kernel_initializer='glorot_normal'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=128, kernel_size=2, padding='same', activation='relu', kernel_initializer='glorot_normal'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=256, kernel_size=2, padding='same', activation='relu', kernel_initializer='glorot_normal'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=512, kernel_size=2, padding='same', activation='relu', kernel_initializer='glorot_normal'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation='relu', kernel_initializer='glorot_normal'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax', kernel_initializer='glorot_normal'))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0e4a2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99203578",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(MODEL_PATH,\"distracted-{epoch:02d}-{val_accuracy:.2f}.hdf5\")\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ae32b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "141/141 [==============================] - ETA: 0s - loss: 252.3154 - accuracy: 0.1321 \n",
      "Epoch 1: val_accuracy improved from -inf to 0.17318, saving model to C:\\Users\\kabeer\\Desktop\\ddd\\model\\self_trained\\distracted-01-0.17.hdf5\n",
      "141/141 [==============================] - 4262s 30s/step - loss: 252.3154 - accuracy: 0.1321 - val_loss: 2.2855 - val_accuracy: 0.1732\n",
      "Epoch 2/25\n",
      "141/141 [==============================] - ETA: 0s - loss: 4.4038 - accuracy: 0.1657 \n",
      "Epoch 2: val_accuracy improved from 0.17318 to 0.25017, saving model to C:\\Users\\kabeer\\Desktop\\ddd\\model\\self_trained\\distracted-02-0.25.hdf5\n",
      "141/141 [==============================] - 2351s 17s/step - loss: 4.4038 - accuracy: 0.1657 - val_loss: 2.2161 - val_accuracy: 0.2502\n",
      "Epoch 3/25\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.7451 - accuracy: 0.1913 \n",
      "Epoch 3: val_accuracy improved from 0.25017 to 0.37737, saving model to C:\\Users\\kabeer\\Desktop\\ddd\\model\\self_trained\\distracted-03-0.38.hdf5\n",
      "141/141 [==============================] - 2304s 16s/step - loss: 2.7451 - accuracy: 0.1913 - val_loss: 1.7566 - val_accuracy: 0.3774\n",
      "Epoch 4/25\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.9708 - accuracy: 0.3716 \n",
      "Epoch 4: val_accuracy improved from 0.37737 to 0.53582, saving model to C:\\Users\\kabeer\\Desktop\\ddd\\model\\self_trained\\distracted-04-0.54.hdf5\n",
      "141/141 [==============================] - 2317s 16s/step - loss: 1.9708 - accuracy: 0.3716 - val_loss: 1.2054 - val_accuracy: 0.5358\n",
      "Epoch 5/25\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.3953 - accuracy: 0.5463 \n",
      "Epoch 5: val_accuracy improved from 0.53582 to 0.71547, saving model to C:\\Users\\kabeer\\Desktop\\ddd\\model\\self_trained\\distracted-05-0.72.hdf5\n",
      "141/141 [==============================] - 2504s 18s/step - loss: 1.3953 - accuracy: 0.5463 - val_loss: 0.8518 - val_accuracy: 0.7155\n",
      "Epoch 6/25\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0114 - accuracy: 0.6690 \n",
      "Epoch 6: val_accuracy did not improve from 0.71547\n",
      "141/141 [==============================] - 2394s 17s/step - loss: 1.0114 - accuracy: 0.6690 - val_loss: 6.7179 - val_accuracy: 0.2136\n",
      "Epoch 7/25\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.6795 - accuracy: 0.7926 \n",
      "Epoch 7: val_accuracy improved from 0.71547 to 0.82526, saving model to C:\\Users\\kabeer\\Desktop\\ddd\\model\\self_trained\\distracted-07-0.83.hdf5\n",
      "141/141 [==============================] - 2358s 17s/step - loss: 0.6795 - accuracy: 0.7926 - val_loss: 0.4760 - val_accuracy: 0.8253\n",
      "Epoch 8/25\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.4703 - accuracy: 0.8507 \n",
      "Epoch 8: val_accuracy improved from 0.82526 to 0.91096, saving model to C:\\Users\\kabeer\\Desktop\\ddd\\model\\self_trained\\distracted-08-0.91.hdf5\n",
      "141/141 [==============================] - 2383s 17s/step - loss: 0.4703 - accuracy: 0.8507 - val_loss: 0.2748 - val_accuracy: 0.9110\n",
      "Epoch 9/25\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.3658 - accuracy: 0.8888 \n",
      "Epoch 9: val_accuracy improved from 0.91096 to 0.95559, saving model to C:\\Users\\kabeer\\Desktop\\ddd\\model\\self_trained\\distracted-09-0.96.hdf5\n",
      "141/141 [==============================] - 2361s 17s/step - loss: 0.3658 - accuracy: 0.8888 - val_loss: 0.1587 - val_accuracy: 0.9556\n",
      "Epoch 10/25\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2677 - accuracy: 0.9179 \n",
      "Epoch 10: val_accuracy did not improve from 0.95559\n",
      "141/141 [==============================] - 7865s 56s/step - loss: 0.2677 - accuracy: 0.9179 - val_loss: 0.2300 - val_accuracy: 0.9317\n",
      "Epoch 11/25\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2320 - accuracy: 0.9288 \n",
      "Epoch 11: val_accuracy improved from 0.95559 to 0.96742, saving model to C:\\Users\\kabeer\\Desktop\\ddd\\model\\self_trained\\distracted-11-0.97.hdf5\n",
      "141/141 [==============================] - 3679s 26s/step - loss: 0.2320 - accuracy: 0.9288 - val_loss: 0.1040 - val_accuracy: 0.9674\n",
      "Epoch 12/25\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2089 - accuracy: 0.9375 \n",
      "Epoch 12: val_accuracy improved from 0.96742 to 0.97545, saving model to C:\\Users\\kabeer\\Desktop\\ddd\\model\\self_trained\\distracted-12-0.98.hdf5\n",
      "141/141 [==============================] - 3141s 22s/step - loss: 0.2089 - accuracy: 0.9375 - val_loss: 0.0851 - val_accuracy: 0.9755\n",
      "Epoch 13/25\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1709 - accuracy: 0.9494 \n",
      "Epoch 13: val_accuracy improved from 0.97545 to 0.97634, saving model to C:\\Users\\kabeer\\Desktop\\ddd\\model\\self_trained\\distracted-13-0.98.hdf5\n",
      "141/141 [==============================] - 3032s 21s/step - loss: 0.1709 - accuracy: 0.9494 - val_loss: 0.0728 - val_accuracy: 0.9763\n",
      "Epoch 14/25\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1810 - accuracy: 0.9501 \n",
      "Epoch 14: val_accuracy improved from 0.97634 to 0.98438, saving model to C:\\Users\\kabeer\\Desktop\\ddd\\model\\self_trained\\distracted-14-0.98.hdf5\n",
      "141/141 [==============================] - 3063s 22s/step - loss: 0.1810 - accuracy: 0.9501 - val_loss: 0.0545 - val_accuracy: 0.9844\n",
      "Epoch 15/25\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1478 - accuracy: 0.9564 \n",
      "Epoch 15: val_accuracy improved from 0.98438 to 0.98639, saving model to C:\\Users\\kabeer\\Desktop\\ddd\\model\\self_trained\\distracted-15-0.99.hdf5\n",
      "141/141 [==============================] - 3107s 22s/step - loss: 0.1478 - accuracy: 0.9564 - val_loss: 0.0498 - val_accuracy: 0.9864\n",
      "Epoch 16/25\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1301 - accuracy: 0.9623 \n",
      "Epoch 16: val_accuracy did not improve from 0.98639\n",
      "141/141 [==============================] - 4210s 30s/step - loss: 0.1301 - accuracy: 0.9623 - val_loss: 0.0785 - val_accuracy: 0.9795\n",
      "Epoch 17/25\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1419 - accuracy: 0.9614 \n",
      "Epoch 17: val_accuracy did not improve from 0.98639\n",
      "141/141 [==============================] - 4407s 31s/step - loss: 0.1419 - accuracy: 0.9614 - val_loss: 0.0676 - val_accuracy: 0.9801\n",
      "Epoch 18/25\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1258 - accuracy: 0.9645 \n",
      "Epoch 18: val_accuracy improved from 0.98639 to 0.98683, saving model to C:\\Users\\kabeer\\Desktop\\ddd\\model\\self_trained\\distracted-18-0.99.hdf5\n",
      "141/141 [==============================] - 3376s 24s/step - loss: 0.1258 - accuracy: 0.9645 - val_loss: 0.0450 - val_accuracy: 0.9868\n",
      "Epoch 19/25\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1120 - accuracy: 0.9692 \n",
      "Epoch 19: val_accuracy did not improve from 0.98683\n",
      "141/141 [==============================] - 4798s 34s/step - loss: 0.1120 - accuracy: 0.9692 - val_loss: 0.0581 - val_accuracy: 0.9839\n",
      "Epoch 20/25\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1249 - accuracy: 0.9663 \n",
      "Epoch 20: val_accuracy did not improve from 0.98683\n",
      "141/141 [==============================] - 4331s 31s/step - loss: 0.1249 - accuracy: 0.9663 - val_loss: 0.0584 - val_accuracy: 0.9848\n",
      "Epoch 21/25\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1182 - accuracy: 0.9680 \n",
      "Epoch 21: val_accuracy did not improve from 0.98683\n",
      "141/141 [==============================] - 4367s 31s/step - loss: 0.1182 - accuracy: 0.9680 - val_loss: 0.0542 - val_accuracy: 0.9868\n",
      "Epoch 22/25\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1121 - accuracy: 0.9705 \n",
      "Epoch 22: val_accuracy improved from 0.98683 to 0.98795, saving model to C:\\Users\\kabeer\\Desktop\\ddd\\model\\self_trained\\distracted-22-0.99.hdf5\n",
      "141/141 [==============================] - 4457s 32s/step - loss: 0.1121 - accuracy: 0.9705 - val_loss: 0.0568 - val_accuracy: 0.9879\n",
      "Epoch 23/25\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1246 - accuracy: 0.9678 \n",
      "Epoch 23: val_accuracy improved from 0.98795 to 0.99264, saving model to C:\\Users\\kabeer\\Desktop\\ddd\\model\\self_trained\\distracted-23-0.99.hdf5\n",
      "141/141 [==============================] - 4489s 32s/step - loss: 0.1246 - accuracy: 0.9678 - val_loss: 0.0292 - val_accuracy: 0.9926\n",
      "Epoch 24/25\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1214 - accuracy: 0.9695 \n",
      "Epoch 24: val_accuracy did not improve from 0.99264\n",
      "141/141 [==============================] - 4443s 32s/step - loss: 0.1214 - accuracy: 0.9695 - val_loss: 0.0456 - val_accuracy: 0.9888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25\n",
      " 86/141 [=================>............] - ETA: 26:56 - loss: 0.1128 - accuracy: 0.9714"
     ]
    }
   ],
   "source": [
    "model_history = model.fit(train_data,validation_data = valid_data,epochs=NUM_EPOCH,shuffle=True,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd68e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
    "ax1.plot(model_history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax1.plot(model_history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "ax1.set_xticks(np.arange(1, 25, 1))\n",
    "ax1.set_yticks(np.arange(0, 1, 0.1))\n",
    "\n",
    "ax2.plot(model_history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax2.plot(model_history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "ax2.set_xticks(np.arange(1, 25, 1))\n",
    "\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40711fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    fig.savefig(os.path.join(MODEL_PATH,\"confusion_matrix.png\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bd3b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_heatmap(n_labels, n_predictions, class_names):\n",
    "    labels = n_labels #sess.run(tf.argmax(n_labels, 1))\n",
    "    predictions = n_predictions #sess.run(tf.argmax(n_predictions, 1))\n",
    "\n",
    "#     confusion_matrix = sess.run(tf.contrib.metrics.confusion_matrix(labels, predictions))\n",
    "    matrix = confusion_matrix(labels,predictions.argmax(axis=1))\n",
    "    row_sum = np.sum(matrix, axis = 1)\n",
    "    w, h = matrix.shape\n",
    "\n",
    "    c_m = np.zeros((w, h))\n",
    "\n",
    "    for i in range(h):\n",
    "        c_m[i] = matrix[i] * 100 / row_sum[i]\n",
    "\n",
    "    c = c_m.astype(dtype = np.uint8)\n",
    "\n",
    "    \n",
    "    heatmap = print_confusion_matrix(c, class_names, figsize=(18,10), fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe4bec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = model.predict(valid_data)\n",
    "\n",
    "valid_list = valid_data.classes.tolist()\n",
    "\n",
    "ypred_class = np.argmax(ypred,axis=1)\n",
    "ytest = valid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e82c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = list()\n",
    "for name,idx in valid_data.class_indices.items():\n",
    "    class_names.append(name)\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124d68f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_heatmap(ytest,ypred,class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821b5967",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(ytest,ypred_class)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(ytest, ypred_class,average='weighted')\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(ytest,ypred_class,average='weighted')\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(ytest,ypred_class,average='weighted')\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d2551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154a2c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d99f44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
